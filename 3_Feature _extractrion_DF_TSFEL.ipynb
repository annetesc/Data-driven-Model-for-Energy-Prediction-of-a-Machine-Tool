{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sms\n",
    "import csv\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from functools import reduce\n",
    "#from sklearn.impute import KNNImputer\n",
    "import secrets\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import Time Series Feature Extraction Library\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!pip install https://github.com/fraunhoferportugal/tsfel/archive/v0.1.2.tar.gz 2>&1\n",
    "!pip install --upgrade -q gspread >/dev/null 2>&1\n",
    "!pip install gspread oauth2client >/dev/null 2>&1\n",
    "!pip install pandas >/dev/null 2>&1\n",
    "!pip install scipy >/dev/null 2>&1\n",
    "!pip install novainstrumentation >/dev/null 2>&1\n",
    "!pip install pandas_profiling >/dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/fraunhoferportugal/tsfel/archive/v0.1.2.tar.gz 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.02  loading MD for:  Durchfluss  from  16.02 with number of datapoints:  12695\n",
      "18.02  loading MD for:  Durchfluss  from  18.02 with number of datapoints:  46298\n",
      "26.04  loading MD for:  Durchfluss  from  26.04 with number of datapoints:  68940\n",
      "28.04  loading MD for:  Durchfluss  from  28.04 with number of datapoints:  133651\n",
      "Total number of datapoints:  261584\n"
     ]
    }
   ],
   "source": [
    "feature = \"Durchfluss\"\n",
    "dates = ['16.02','18.02','26.04','28.04']\n",
    "#dates = ['28.04']\n",
    "list_dfs_MD = []\n",
    "list_dfs_data = []\n",
    "for i in range(len(dates)):\n",
    "    date = dates[i]  \n",
    "    orig_folder = 'C:/Users/Anni/CS/_sig_crun/ReLkat/data/data_csv/'+date+\"/\"\n",
    "    df_MD = pd.read_csv(os.path.join(orig_folder,\"MD_\"+feature+\"_\"+date+\".csv\"),index_col = 0)\n",
    "    data_df = pd.read_csv(os.path.join(orig_folder,date+\"_total.csv\"),index_col = 0)\n",
    "    list_dfs_MD.append(df_MD)\n",
    "    list_dfs_data.append(data_df)\n",
    "    print(date,\" loading MD for: \",feature,\" from \", date, \"with number of datapoints: \",df_MD.shape[0])\n",
    "df_MD_total = pd.concat(list_dfs_MD)\n",
    "df_MD_total.reset_index(drop=True,inplace=True)\n",
    "print(\"Total number of datapoints: \",df_MD_total.shape[0])\n",
    "df_cycle_times = pd.concat(list_dfs_data)\n",
    "df_cycle_times = df_cycle_times[[\"start_time\",\"end_time\",\"cycle_time\"]]\n",
    "df_cycle_times['cycle_time'] = (df_cycle_times['cycle_time']).apply(lambda x: str(x)[10:22])\n",
    "df_cycle_times['cycle_time'] =  (df_cycle_times['cycle_time']).apply(lambda x: datetime.datetime.strptime(x,'%M:%S.%f'))\n",
    "df_cycle_times['cycle_time'] = (df_cycle_times['cycle_time']).apply(lambda x:datetime.timedelta(minutes=x.minute,seconds=x.second,microseconds=x.microsecond).total_seconds())\n",
    "mms = MinMaxScaler()\n",
    "df_cycle_times[['cycle_time']] = mms.fit_transform(df_cycle_times[['cycle_time']])\n",
    "MD = df_MD_total\n",
    "MD.sort_values(by=['sys_time'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261583, 7)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 700)\n",
    "start_time = '2021-02-16 11:55:05.876769333'\n",
    "end_time = '2021-04-28 18:01:48.559682659'\n",
    "MD.drop(['uuid','plc_time','sequence_number','value_string','value_bytes','identifier'],axis=1,inplace=True)\n",
    "MD['start_cycle'] = np.datetime64('NaT')\n",
    "MD['end_cycle'] = np.datetime64('NaT')\n",
    "MD['end_cycle'] = np.where((MD['label'].str.contains('Taktzeit 1 Start '))&(MD['value_bool']==False),MD['sys_time'],np.datetime64('NaT'))\n",
    "MD.loc[(MD['value_bool']==True),\"start_cycle\"] = MD['sys_time']\n",
    "MD = MD[(MD['sys_time']>= start_time)&(MD['sys_time']<= end_time)]\n",
    "MD.sort_values(by=['sys_time'],inplace=True)\n",
    "MD.reset_index(drop=True,inplace=True)\n",
    "print(MD.shape)\n",
    "\n",
    "# MD['sys_time'] = MD['sys_time'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD['cycle'] = MD['value_bool'][~MD['start_cycle'].isnull()]*np.array([i for i in range(MD['start_cycle'].nunique())])\n",
    "MD['cycle'].fillna(method='ffill',inplace=True)\n",
    "\n",
    "MD = MD[~((MD['cycle']==3)|(MD['cycle']==4))]\n",
    "MD.reset_index(drop=True,inplace=True)\n",
    "MD['cycle'] = MD['value_bool'][~MD['start_cycle'].isnull()]*np.array([i for i in range(MD['start_cycle'].nunique())])\n",
    "MD['cycle'].fillna(method='ffill',inplace=True)\n",
    "MD.sort_values(by=['sys_time'],inplace=True)\n",
    "#grouped = MD.groupby('cycle').size()    #agg('count')    #filter(lambda x: x['Count'].min()>8 )\n",
    "#grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12      2156\n",
       "8420    1732\n",
       "29      1727\n",
       "8432    1673\n",
       "39      1671\n",
       "        ... \n",
       "4679       1\n",
       "7720       1\n",
       "709        1\n",
       "2532       1\n",
       "3112       1\n",
       "Name: cycle, Length: 8468, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nr. of cycles and their length\n",
    "print(MD['cycle'].nunique())\n",
    "MD['cycle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0\n",
       "16           1\n",
       "32           2\n",
       "1358         3\n",
       "2702         4\n",
       "          ... \n",
       "251293    8463\n",
       "252795    8464\n",
       "254375    8465\n",
       "255789    8466\n",
       "257192    8467\n",
       "Name: value_bool, Length: 8468, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check start index of cycles\n",
    "MD['value_bool'][~MD['start_cycle'].isnull()]*np.array([i for i in range(MD['start_cycle'].nunique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kühlschmierstoff: Durchfluss ND Vorlauf  in l/min (DB_PROZESSWERTE.iw_450_93 )',\n",
       " 'Kühlschmierstoff: Durchfluss HD Vorlauf in l/min (DB_PROZESSWERTE.iw_450_92 )']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(MD['label'].unique())[1:]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = []\n",
    "for feature in features:\n",
    "    df_feature = MD[MD['label']==feature][['sys_time','value_integer','value_double']]\n",
    "    df_feature[feature] = np.where(df_feature['value_integer'].isnull(),df_feature['value_double'],df_feature['value_integer'])\n",
    "    df_feature.drop(['value_integer','value_double'],axis=1,inplace=True)\n",
    "    df_features.append(df_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MD = reduce(lambda left,right: pd.merge(left,right,on=['sys_time'],how='outer'), df_features)\n",
    "df_MD.sort_values(by=['sys_time'],inplace=True)\n",
    "df_MD.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.02  loading data from  16.02 with number of datapoints:  (6, 2)\n",
      "18.02  loading data from  18.02 with number of datapoints:  (27, 2)\n",
      "26.04  loading data from  26.04 with number of datapoints:  (27, 2)\n",
      "28.04  loading data from  28.04 with number of datapoints:  (84, 2)\n",
      "(144, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load times of start and end for all the cycles from existing df\n",
    "dates = ['16.02','18.02','26.04','28.04']\n",
    "list_dfs = []\n",
    "max_length = 0\n",
    "for i in range(len(dates)):\n",
    "    date = dates[i]\n",
    "    orig_folder = 'C:/Users/Anni/CS/_sig_crun/Relkat/data/data_csv/'+date+\"/\"\n",
    "    data_df = pd.read_csv(os.path.join(orig_folder,date+\"_total.csv\"),index_col = 0)\n",
    "    data_df = data_df[[\"start_time\",\"end_time\"]]\n",
    "    list_dfs.append(data_df)\n",
    "    print(date,\" loading data from \", date, \"with number of datapoints: \",data_df.shape)    \n",
    "df_total = pd.concat(list_dfs)\n",
    "df_total.reset_index(drop=True,inplace=True)\n",
    "print(df_total.shape)\n",
    "start_cycle = np.array(df_total['start_time'])\n",
    "end_cycle = np.array(df_total['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236563, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_MD.shape)\n",
    "df_MD.loc[0,'Kühlschmierstoff: Durchfluss HD Vorlauf in l/min (DB_PROZESSWERTE.iw_450_92 )']=0\n",
    "df_MD.fillna(method='ffill',inplace=True)\n",
    "MD.sort_values(by=['sys_time'],inplace=True)\n",
    "#df_MD.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys_time</th>\n",
       "      <th>Kühlschmierstoff: Durchfluss ND Vorlauf  in l/min (DB_PROZESSWERTE.iw_450_93 )</th>\n",
       "      <th>Kühlschmierstoff: Durchfluss HD Vorlauf in l/min (DB_PROZESSWERTE.iw_450_92 )</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-16 11:55:06.416670285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-16 11:55:06.431654429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-16 11:55:06.461913834</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2021-02-16 11:55:06.482242402</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2021-02-16 11:55:06.511932771</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236558</td>\n",
       "      <td>2021-04-28 18:01:31.870234970</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236559</td>\n",
       "      <td>2021-04-28 18:01:31.934427505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236560</td>\n",
       "      <td>2021-04-28 18:01:31.965102276</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236561</td>\n",
       "      <td>2021-04-28 18:01:31.979857696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236562</td>\n",
       "      <td>2021-04-28 18:01:31.995068320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236563 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sys_time  \\\n",
       "0       2021-02-16 11:55:06.416670285   \n",
       "1       2021-02-16 11:55:06.431654429   \n",
       "2       2021-02-16 11:55:06.461913834   \n",
       "3       2021-02-16 11:55:06.482242402   \n",
       "4       2021-02-16 11:55:06.511932771   \n",
       "...                               ...   \n",
       "236558  2021-04-28 18:01:31.870234970   \n",
       "236559  2021-04-28 18:01:31.934427505   \n",
       "236560  2021-04-28 18:01:31.965102276   \n",
       "236561  2021-04-28 18:01:31.979857696   \n",
       "236562  2021-04-28 18:01:31.995068320   \n",
       "\n",
       "        Kühlschmierstoff: Durchfluss ND Vorlauf  in l/min (DB_PROZESSWERTE.iw_450_93 )  \\\n",
       "0                                                     1.0                                \n",
       "1                                                     2.0                                \n",
       "2                                                     3.0                                \n",
       "3                                                     4.0                                \n",
       "4                                                     5.0                                \n",
       "...                                                   ...                                \n",
       "236558                                                6.0                                \n",
       "236559                                                5.0                                \n",
       "236560                                                3.0                                \n",
       "236561                                                1.0                                \n",
       "236562                                                0.0                                \n",
       "\n",
       "        Kühlschmierstoff: Durchfluss HD Vorlauf in l/min (DB_PROZESSWERTE.iw_450_92 )  \n",
       "0                                                     0.0                              \n",
       "1                                                     0.0                              \n",
       "2                                                     0.0                              \n",
       "3                                                     0.0                              \n",
       "4                                                     0.0                              \n",
       "...                                                   ...                              \n",
       "236558                                                0.0                              \n",
       "236559                                                0.0                              \n",
       "236560                                                0.0                              \n",
       "236561                                                0.0                              \n",
       "236562                                                0.0                              \n",
       "\n",
       "[236563 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ND = df_MD.drop(['Kühlschmierstoff: Durchfluss HD Vorlauf in l/min (DB_PROZESSWERTE.iw_450_92 )'],axis=1)\n",
    "df_HD = df_MD.drop(['Kühlschmierstoff: Durchfluss ND Vorlauf  in l/min (DB_PROZESSWERTE.iw_450_93 )'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of datapoints that are gonna be used - starting from the beginning of the time series\n",
    "df_HD_cycles = []\n",
    "min_len = 1300\n",
    "\n",
    "for i in range(len(start_cycle)):\n",
    "    HD_cycle = df_HD[(df_HD['sys_time']>=start_cycle[i])&(df_HD['sys_time']<=end_cycle[i])].drop('sys_time',axis=1).values\n",
    "    \n",
    "    #print(len(HD_cycle))\n",
    "   \n",
    "    if(len(HD_cycle) > min_len):\n",
    "        HD_cycle = HD_cycle[:min_len]\n",
    "        #print(HD_cycle.shape)\n",
    "    else:\n",
    "        pad_len = min_len - len(HD_cycle)\n",
    "        HD_cycle = np.pad(HD_cycle.reshape(len(HD_cycle),), (0,pad_len), 'constant', constant_values=(0))\n",
    "        #print(HD_cycle.shape)\n",
    "    df_HD_cycles.append(HD_cycle.reshape(len(HD_cycle),1))\n",
    "   #print('_______________')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure array has time series of equal length for every cycle\n",
    "ar_DF_KSS_HD = np.vstack(df_HD_cycles)\n",
    "ar_DF_KSS_HD.shape[0]/1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of datapoints that are used - starting from the end of the time series\n",
    "df_ND_cycles = []\n",
    "min_len = 800\n",
    "\n",
    "for i in range(len(start_cycle)):\n",
    "    ND_cycle = df_ND[(df_ND['sys_time']>=start_cycle[i])&(df_ND['sys_time']<=end_cycle[i])].drop('sys_time',axis=1).values\n",
    "    \n",
    "    #print(len(ND_cycle))\n",
    "    \n",
    "    if(len(ND_cycle) > min_len):\n",
    "        ND_cycle = ND_cycle[-min_len:]\n",
    "        #print(ND_cycle.shape)\n",
    "    else:\n",
    "        pad_len = min_len - len(ND_cycle)\n",
    "        ND_cycle = np.pad(ND_cycle.reshape(len(ND_cycle),), (pad_len,0), 'constant', constant_values=(0))\n",
    "        #print(ND_cycle.shape)\n",
    "    df_ND_cycles.append(ND_cycle.reshape(len(ND_cycle),1))\n",
    "    #print('_______________')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure array has time series of equal length for every cycle\n",
    "ar_DF_KSS_ND = np.vstack(df_ND_cycles)\n",
    "ar_DF_KSS_ND.shape[0]/800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'DF_KSS_HD'\n",
    "ar = ar_DF_KSS_HD\n",
    "\n",
    "dest_folder = \"C:/Users/.../MD_feature_arrays/\"\n",
    "filename = \"ar_\"+feature\n",
    "np.save(os.path.join(dest_folder,filename)+\".npy\", ar)\n",
    "print(os.path.join(dest_folder,filename)+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feat_array(feat_name,ar,window_size):\n",
    "    cfg_file_stat = tsfel.get_features_by_domain('statistical')                                         \n",
    "    ar_feat_stat = tsfel.time_series_features_extractor(cfg_file_stat, ar, window_size=window_size)\n",
    "    \n",
    "    # Remove highly correlated features\n",
    "    corr_features = tsfel.correlated_features(ar_feat_stat)\n",
    "    ar_feat_stat.drop(corr_features, axis=1, inplace=True)\n",
    "    \n",
    "    # Remove low variance features\n",
    "    selector = VarianceThreshold()\n",
    "    ar_feat_stat = selector.fit_transform(ar_feat_stat)\n",
    "    print(ar_feat_stat.shape) \n",
    "    \n",
    "    # Normalize Features\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    ar_feat_stat_norm = scaler.fit_transform(ar_feat_stat)\n",
    "\n",
    "\n",
    "    cfg_file_temp = tsfel.get_features_by_domain('temporal')                                         \n",
    "    ar_feat_temp = tsfel.time_series_features_extractor(cfg_file_temp, ar, window_size=window_size)\n",
    "    corr_features = tsfel.correlated_features(ar_feat_temp)\n",
    "    ar_feat_temp.drop(corr_features, axis=1, inplace=True)\n",
    "    selector = VarianceThreshold()\n",
    "    ar_feat_temp = selector.fit_transform(ar_feat_temp)\n",
    "    print(ar_feat_temp.shape) \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    ar_feat_temp_norm = scaler.fit_transform(ar_feat_temp)\n",
    "    ar_feat_total_norm = np.concatenate([ar_feat_stat_norm,ar_feat_temp_norm],axis=1)\n",
    "    print(ar_feat_total_norm.shape)\n",
    "\n",
    "    return ar_feat_total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_KSS_HD_feat_total_norm = create_feat_array(\"DF_KSS_HD\",ar_DF_KSS_ND,1300)\n",
    "ar_KSS_ND_feat_total_norm = create_feat_array(\"DF_KSS_ND\",ar_DF_KSS_ND,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
